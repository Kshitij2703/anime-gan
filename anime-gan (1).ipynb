{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":627400,"sourceType":"datasetVersion","datasetId":308470}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-10-29T16:55:01.494479Z","iopub.execute_input":"2024-10-29T16:55:01.495408Z","iopub.status.idle":"2024-10-29T16:55:13.045743Z","shell.execute_reply.started":"2024-10-29T16:55:01.495364Z","shell.execute_reply":"2024-10-29T16:55:13.044488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision.utils import save_image, make_grid\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(1)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T16:58:59.736931Z","iopub.execute_input":"2024-10-29T16:58:59.737703Z","iopub.status.idle":"2024-10-29T16:58:59.747836Z","shell.execute_reply.started":"2024-10-29T16:58:59.737661Z","shell.execute_reply":"2024-10-29T16:58:59.746875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters\nbatch_size = 64\nlatent_dim = 100  # Dimension of the noise vector\nimage_shape = (3, 64, 64)  # Shape of images (3 channels, 64x64 resolution)\nsample_fraction = 0.4  # Using 40% of the dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T16:59:06.144370Z","iopub.execute_input":"2024-10-29T16:59:06.145350Z","iopub.status.idle":"2024-10-29T16:59:06.150024Z","shell.execute_reply.started":"2024-10-29T16:59:06.145300Z","shell.execute_reply":"2024-10-29T16:59:06.148836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define transformations\ntrain_transform = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5] * 3, [0.5] * 3)  # Normalization for GAN training\n])\n\n# Custom dataset class\nclass ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, folder_path, transform=None):\n        self.folder_path = folder_path\n        self.transform = transform\n        self.image_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(('jpg', 'jpeg', 'png'))]\n\n        # Limit the dataset to 40% of the images\n        subset_size = int(len(self.image_files) * sample_fraction)\n        self.image_files = np.random.choice(self.image_files, subset_size, replace=False)\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        image_path = self.image_files[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image\n\n# Initialize dataset and DataLoader\ntrain_data_path = '/kaggle/input/selfie2anime/trainB'\ntrain_dataset = ImageDataset(folder_path=train_data_path, transform=train_transform)\ndataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T17:01:05.619478Z","iopub.execute_input":"2024-10-29T17:01:05.619895Z","iopub.status.idle":"2024-10-29T17:01:05.645640Z","shell.execute_reply.started":"2024-10-29T17:01:05.619855Z","shell.execute_reply":"2024-10-29T17:01:05.644888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, latent_dim):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.ConvTranspose2d(latent_dim, 512, kernel_size=4, stride=1, padding=0),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        return self.model(z)\n\n# Instantiate and move to device\ngenerator = Generator(latent_dim).to(device)\nsummary(generator, (latent_dim, 1, 1))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T17:02:14.141910Z","iopub.execute_input":"2024-10-29T17:02:14.142673Z","iopub.status.idle":"2024-10-29T17:02:15.246519Z","shell.execute_reply.started":"2024-10-29T17:02:14.142629Z","shell.execute_reply":"2024-10-29T17:02:15.245422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n            nn.Sigmoid()\n        )\n\n    def forward(self, img):\n        return self.model(img).view(-1, 1).squeeze(1)\n\n# Instantiate and move to device\ndiscriminator = Discriminator().to(device)\nsummary(discriminator, (3, 64, 64))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T17:02:24.025358Z","iopub.execute_input":"2024-10-29T17:02:24.025717Z","iopub.status.idle":"2024-10-29T17:02:24.283020Z","shell.execute_reply.started":"2024-10-29T17:02:24.025685Z","shell.execute_reply":"2024-10-29T17:02:24.282109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss function\nadversarial_loss = nn.BCELoss()\n\n# Optimizers\nlr = 0.0002\nbetas = (0.5, 0.999)\noptimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)\noptimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T17:02:35.667791Z","iopub.execute_input":"2024-10-29T17:02:35.668188Z","iopub.status.idle":"2024-10-29T17:02:35.674374Z","shell.execute_reply.started":"2024-10-29T17:02:35.668145Z","shell.execute_reply":"2024-10-29T17:02:35.673336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(epoch, fixed_noise):\n    generator.eval()\n    with torch.no_grad():\n        generated_images = generator(fixed_noise).detach().cpu()\n    grid = make_grid(generated_images, nrow=8, normalize=True)\n    save_image(grid, f\"generated_images_epoch_{epoch}.png\")\n    plt.imshow(grid.permute(1, 2, 0))\n    plt.axis(\"off\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T17:02:47.382732Z","iopub.execute_input":"2024-10-29T17:02:47.383686Z","iopub.status.idle":"2024-10-29T17:02:47.389484Z","shell.execute_reply.started":"2024-10-29T17:02:47.383638Z","shell.execute_reply":"2024-10-29T17:02:47.388504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_losses = []\ng_losses = []\nfrom PIL import Image\n\nnum_epochs = 250\nfixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)  # Fixed noise for consistent image generation\n\nfor epoch in range(num_epochs):\n    for i, imgs in enumerate(dataloader):  # Modified to only unpack imgs\n        # Prepare real and fake data\n        real_imgs = imgs.to(device)\n        real_labels = torch.ones(imgs.size(0), device=device)  # Changed to match discriminator output size\n        fake_labels = torch.zeros(imgs.size(0), device=device)  # Changed to match discriminator output size\n        \n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n        optimizer_D.zero_grad()\n        \n        # Real images\n        real_loss = adversarial_loss(discriminator(real_imgs), real_labels)\n        \n        # Fake images\n        z = torch.randn(imgs.size(0), latent_dim, 1, 1, device=device)\n        fake_imgs = generator(z)\n        fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), fake_labels)\n        \n        # Discriminator loss\n        d_loss = (real_loss + fake_loss) / 2\n        d_loss.backward()\n        optimizer_D.step()\n        \n        # -----------------\n        #  Train Generator\n        # -----------------\n        optimizer_G.zero_grad()\n        \n        # Generate fake images\n        fake_imgs = generator(z)\n        g_loss = adversarial_loss(discriminator(fake_imgs), real_labels)\n        \n        # Generator loss\n        g_loss.backward()\n        optimizer_G.step()\n        \n        # Log progress\n        if i % 100 == 0:\n            print(f\"Epoch [{epoch}/{num_epochs}] Batch [{i}/{len(dataloader)}] \"\n                  f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n    \n    # Save generated images every epoch\n    generate_and_save_images(epoch, fixed_noise)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T17:19:31.087317Z","iopub.execute_input":"2024-10-29T17:19:31.088151Z","iopub.status.idle":"2024-10-29T17:43:32.577838Z","shell.execute_reply.started":"2024-10-29T17:19:31.088110Z","shell.execute_reply":"2024-10-29T17:43:32.576960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Assuming generator and discriminator are your model instances\ntorch.save(generator.state_dict(), \"generator.pth\")\ntorch.save(discriminator.state_dict(), \"discriminator.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T17:52:47.607924Z","iopub.execute_input":"2024-10-29T17:52:47.608346Z","iopub.status.idle":"2024-10-29T17:52:47.647111Z","shell.execute_reply.started":"2024-10-29T17:52:47.608310Z","shell.execute_reply":"2024-10-29T17:52:47.646270Z"},"trusted":true},"execution_count":null,"outputs":[]}]}